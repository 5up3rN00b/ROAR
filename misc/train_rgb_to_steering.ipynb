{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b6d9839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "from keras import __version__ as keras_version\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5da7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2bb07c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_vehicle_states(dir: Path, regex=\"/*.npy\") -> np.ndarray:\n",
    "    file_paths = sorted(glob.glob((dir.as_posix() + regex)), key=os.path.getmtime)\n",
    "    states = []\n",
    "    for fpath in file_paths:\n",
    "        state = np.load(fpath, allow_pickle=True)\n",
    "        states.append(state)\n",
    "    return np.array(states)\n",
    "\n",
    "\n",
    "def load_images(image_dir: Path, regex=\"/*.png\") -> List:\n",
    "    file_paths = sorted(glob.glob((image_dir.as_posix() + regex)), key=os.path.getmtime)\n",
    "    images = []\n",
    "    for fpath in file_paths:\n",
    "        image = cv2.imread(fpath)\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "\n",
    "def load_depth_images(dir, regex=\"/*.npy\") -> List:\n",
    "    file_paths = sorted(glob.glob((dir.as_posix() + regex)), key=os.path.getmtime)\n",
    "    images = []\n",
    "    for fpath in file_paths:\n",
    "        image = np.load(fpath)\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    rgb_images = load_images(Path(\"../data/output/front_rgb/\"), regex=\"/frame_*\")\n",
    "    vehicle_states = load_vehicle_states(dir=Path(\"../data/output/vehicle_state\"))\n",
    "    # depth_images = load_depth_images(dir=Path(\"../data/output/front_depth\"))\n",
    "    X = rgb_images\n",
    "    y = np.array(vehicle_states)[:, -1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def plot_steering_hist(steerings: np.ndarray):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "    ax.grid(True)\n",
    "    ax.set(title=\"Ensemble - Distribution of steering angles\")\n",
    "    count, bins, _ = ax.hist(steerings, bins=25, histtype='bar')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def fliph_image(img):\n",
    "    \"\"\"\n",
    "    Returns a horizontally flipped image\n",
    "    \"\"\"\n",
    "    return cv2.flip(img, 1)\n",
    "\n",
    "\n",
    "def blur_image(img, f_size=5):\n",
    "    \"\"\"\n",
    "    Applies Gaussir Blur to smoothen the image.\n",
    "    This in effect performs anti-aliasing on the provided image\n",
    "    \"\"\"\n",
    "    img = cv2.GaussianBlur(img, (f_size, f_size), 0)\n",
    "    img = np.clip(img, 0, 255)\n",
    "\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def translate_image(img, st_angle, low_x_range, high_x_range, low_y_range, high_y_range, delta_st_angle_per_px):\n",
    "    \"\"\"\n",
    "    Shifts the image right, left, up or down.\n",
    "    When performing a lateral shift, a delta proportional to the pixel shifts is added to the current steering angle\n",
    "    \"\"\"\n",
    "    rows, cols = (img.shape[0], img.shape[1])\n",
    "    translation_x = np.random.randint(low_x_range, high_x_range)\n",
    "    translation_y = np.random.randint(low_y_range, high_y_range)\n",
    "\n",
    "    st_angle += translation_x * delta_st_angle_per_px\n",
    "\n",
    "    translation_matrix = np.float32([[1, 0, translation_x], [0, 1, translation_y]])\n",
    "    img = cv2.warpAffine(img, translation_matrix, (cols, rows))\n",
    "\n",
    "    return img, st_angle\n",
    "\n",
    "\n",
    "def change_image_lightness(img, low, high):\n",
    "    \"\"\"\n",
    "    Applies an offset in [low, high] interval to change the 'L' component of the supplied image in HSL format\n",
    "    The returned image in converted back to RGB\n",
    "    \"\"\"\n",
    "    # Convert to HSL (HLS in OpenCV!!)\n",
    "    hls = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_RGB2HLS)\n",
    "    hls = hls.astype(int)\n",
    "\n",
    "    # Add an offset to light component\n",
    "    offset = np.random.randint(low, high=high)\n",
    "    # Since the format is HLS and NOT HSL, it is the second component (index 1) that is modified\n",
    "    # hls[:,:,1] += offset\n",
    "    hls[:, :, 1] = offset\n",
    "\n",
    "    # Make sure our lightness component is in the interval [0, 255]\n",
    "    np.clip(hls, 0, 255)\n",
    "\n",
    "    # Convert back to uint\n",
    "    hls = hls.astype(np.uint8)\n",
    "\n",
    "    # Make sure we return image in RGB format\n",
    "    return cv2.cvtColor(hls, cv2.COLOR_HLS2RGB)\n",
    "\n",
    "\n",
    "def change_image_brightness(img, low, high):\n",
    "    \"\"\"\n",
    "    Applies an offset in [low, high] interval to change the 'V' component of the supplied image in HSV format\n",
    "    The returned image in converted back to RGB\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to HSV\n",
    "    hsv = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_RGB2HSV)\n",
    "    hsv = hsv.astype(int)\n",
    "\n",
    "    # Adding the offset to the v component\n",
    "    offset = np.random.randint(low, high=high)\n",
    "    hsv[:, :, 2] += offset\n",
    "\n",
    "    # Make sure our lightness component is in the interval [0, 255]\n",
    "    np.clip(hsv, 0, 255)\n",
    "\n",
    "    # Convert back to uint\n",
    "    hsv = hsv.astype(np.uint8)\n",
    "\n",
    "    # Make sure we return image in RGB format\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "\n",
    "def add_random_shadow(img, w_low=0.6, w_high=0.85):\n",
    "    \"\"\"\n",
    "    Overlays supplied image with a random shadow poligon\n",
    "    The weight range (i.e. darkness) of the shadow can be configured via the interval [w_low, w_high)\n",
    "    \"\"\"\n",
    "    cols, rows = (img.shape[0], img.shape[1])\n",
    "\n",
    "    top_y = np.random.random_sample() * rows\n",
    "    bottom_y = np.random.random_sample() * rows\n",
    "    bottom_y_right = bottom_y + np.random.random_sample() * (rows - bottom_y)\n",
    "    top_y_right = top_y + np.random.random_sample() * (rows - top_y)\n",
    "    if np.random.random_sample() <= 0.5:\n",
    "        bottom_y_right = bottom_y - np.random.random_sample() * (bottom_y)\n",
    "        top_y_right = top_y - np.random.random_sample() * (top_y)\n",
    "\n",
    "    poly = np.asarray([[[top_y, 0], [bottom_y, cols], [bottom_y_right, cols], [top_y_right, 0]]], dtype=np.int32)\n",
    "\n",
    "    mask_weight = np.random.uniform(w_low, w_high)\n",
    "    origin_weight = 1 - mask_weight\n",
    "\n",
    "    mask = np.copy(img).astype(np.int32)\n",
    "    cv2.fillPoly(mask, poly, (0, 0, 0))\n",
    "    # masked_image = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    return cv2.addWeighted(img.astype(np.int32), origin_weight, mask, mask_weight, 0).astype(np.uint8)\n",
    "\n",
    "\n",
    "def shift_horizon(img, h_s=0.2):\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    # randomly shift horizon\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    horizon = h_s * height / 3\n",
    "    v_shift = np.random.randint(-height / 8, height / 8)\n",
    "    pts1 = np.float32([[0, horizon], [width, horizon], [0, height], [width, height]])\n",
    "    pts2 = np.float32([[0, horizon + v_shift], [width, horizon + v_shift], [0, height], [width, height]])\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    img = cv2.warpPerspective(img, M, (width, height), borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def change_image_brightness_rgb(img, s_low=0.2, s_high=0.75):\n",
    "    \"\"\"\n",
    "    Changes the image brightness by multiplying all RGB values by the same scalacar in [s_low, s_high).\n",
    "    Returns the brightness adjusted image in RGB format.\n",
    "    \"\"\"\n",
    "    img = img.astype(np.float32)\n",
    "    s = np.random.uniform(s_low, s_high)\n",
    "    img[:, :, :] *= s\n",
    "    np.clip(img, 0, 255)\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def augment_image(img, st_angle, p=1.0):\n",
    "    \"\"\"\n",
    "    Augment a given image, by applying a series of transformations, with a probability p.\n",
    "    The steering angle may also be modified.\n",
    "    Returns the tuple (augmented_image, new_steering_angle)\n",
    "    \"\"\"\n",
    "    aug_img = img\n",
    "\n",
    "    # if np.random.random_sample() <= 1.0:\n",
    "    # Reduce aliasing via blurring\n",
    "    # aug_img = blur_image(aug_img)\n",
    "\n",
    "    if np.random.random_sample() <= 0.5:\n",
    "        # Horizontally flip image\n",
    "        aug_img = fliph_image(aug_img)\n",
    "        st_angle = -st_angle\n",
    "\n",
    "    if np.random.random_sample() <= 0.5:\n",
    "        aug_img = change_image_brightness_rgb(aug_img)\n",
    "\n",
    "    if np.random.random_sample() <= 0.5:\n",
    "        aug_img = add_random_shadow(aug_img, w_low=0.45)\n",
    "\n",
    "    if np.random.random_sample() <= 0.5:\n",
    "        # Shift the image left/right, up/down and modify the steering angle accordingly\n",
    "        aug_img, st_angle = translate_image(aug_img, st_angle, -60, 61, -20, 21, 0.35 / 100.0)\n",
    "    return aug_img, st_angle\n",
    "\n",
    "\n",
    "def generate_images(X, y, batch_size, shuffle=True, aug_likelihood=0.5, data_aug_pct=0.8):\n",
    "    num_images, width, height, channel = np.shape(X)\n",
    "    assert num_images == len(y), f\"Dimension mismatch: Got {num_images} X but {len(y)} y\"\n",
    "    batch = np.zeros((batch_size, width, height, channel), dtype=np.float32)\n",
    "    steering_angles = np.zeros(batch_size)\n",
    "    while True:\n",
    "        k = 0\n",
    "        while k < batch_size:\n",
    "            idx = np.random.randint(0, num_images)\n",
    "            image = X[idx]\n",
    "            steering_angle = y[idx]\n",
    "            img, st_angle = None, None\n",
    "            if np.random.random_sample() <= data_aug_pct:\n",
    "                img, st_angle = augment_image(img=image, st_angle=steering_angle, p=aug_likelihood)\n",
    "            else:\n",
    "                img, st_angle = image, steering_angle\n",
    "            batch[k] = img\n",
    "            steering_angles[k] = st_angle\n",
    "            k += 1\n",
    "        yield batch, np.clip(steering_angles, -1, 1)\n",
    "\n",
    "\n",
    "def show_images(imgs, labels, cols=5, fig_size=(15, 5)):\n",
    "    rows = len(imgs) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=fig_size)\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            ax = axes[r, c]\n",
    "            img = imgs[cols * r + c]\n",
    "            lb = labels[cols * r + c]\n",
    "            ax.imshow(img.astype(np.uint8))\n",
    "            ax.axis('on')\n",
    "            ax.set_aspect('equal')\n",
    "            ax.set(title=lb)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_sample_images(X, y):\n",
    "    gen = generate_images(X=X, y=y, batch_size=20)\n",
    "    b, s = next(gen)\n",
    "    show_images(b[0:20], s[0:20])\n",
    "\n",
    "\n",
    "def plot_results(hist, metrics, xlb, ylb, title, leg, fsize=(10, 5)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=fsize)\n",
    "    for m in metrics:\n",
    "        ax.plot(hist.history[m])\n",
    "\n",
    "    ax.set(xlabel=xlb, ylabel=ylb, title=title)\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    ax.legend(leg, loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def generate_train_test_split(X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    print(\"Feeding data to tensorflow now\")\n",
    "    X_train, X_test, y_train, y_test = tf.stack(X_train), tf.stack(X_test), tf.stack(y_train), tf.stack(y_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc71e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecd9459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 398, 24)      1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 298, 398, 24)      96        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 197, 36)      21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 147, 197, 36)      144       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 97, 48)        43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 72, 97, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 70, 95, 64)        27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 70, 95, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 68, 93, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 68, 93, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 404736)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               80947400  \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 81,091,303\n",
      "Trainable params: 81,090,311\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from model import nvidia_model\n",
    "m = nvidia_model()\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e680ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "gen = generate_images(X, y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbdabf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3670/Unknown - 380s 101ms/step - loss: 0.0474"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss', min_delta=0.05, patience=5, verbose=1, mode=\"min\"\n",
    "    )\n",
    "]\n",
    "history = m.fit(gen, verbose=1, callbacks=callbacks, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2fd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
