{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec3bd95",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8019d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e535acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b43c9",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a1ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vehicle_states(dir: Path, regex=\"/*.npy\") -> List[str]:\n",
    "    file_paths = sorted(glob.glob((dir.as_posix() + regex)), key=os.path.getmtime)\n",
    "    return file_paths\n",
    "\n",
    "def load_images(dir: Path, regex=\"/*.png\") -> List:\n",
    "    file_paths = sorted(glob.glob((image_dir.as_posix() + regex)), key=os.path.getmtime)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def load_depth_images(dir, regex=\"/*.npy\") -> List:\n",
    "    file_paths = sorted(glob.glob((dir.as_posix() + regex)), key=os.path.getmtime)\n",
    "    return file_paths\n",
    "\n",
    "def load_data_paths():\n",
    "    #rgb_images = load_images(Path(\"../data/output/front_rgb/\"), regex=\"/frame_*\")\n",
    "    vehicle_states_paths = load_vehicle_states(dir=Path(\"../data/output/vehicle_state\"))\n",
    "    depth_images_paths = load_depth_images(dir=Path(\"../data/output/front_depth\"))\n",
    "    X = depth_images_paths\n",
    "    y = vehicle_states_paths\n",
    "    \n",
    "    X = np.array(X[0: min(len(X), len(y))])\n",
    "    y = np.array(y[0: min(len(X), len(y))])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e066bc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4234 training and 43 testing data for a total of 4277\n"
     ]
    }
   ],
   "source": [
    "X_paths, y_paths = load_data_paths()\n",
    "test_ratio = 0.01\n",
    "length = len(X_paths)\n",
    "indices = np.random.permutation(length)\n",
    "num_train = int(length * (1-test_ratio))\n",
    "training_idx, test_idx = indices[:num_train], indices[num_train:]\n",
    "X_paths_train, X_paths_test, y_paths_train, y_paths_test = X_paths[training_idx], X_paths[test_idx], y_paths[training_idx], y_paths[test_idx]\n",
    "\n",
    "print(f\"Found {len(X_paths_train)} training and {len(X_paths_test)} testing data for a total of {len(X_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15bba9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55b0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state(fpath):\n",
    "    state = np.load(fpath, allow_pickle=True)\n",
    "    return state\n",
    "def load_depth(fpath):\n",
    "    image = np.expand_dims(np.load(fpath), -1)\n",
    "    return image\n",
    "def generate_data(X_paths, y_paths, batch_size=16, shuffle=True, \n",
    "                    aug_likelihood=0.5, \n",
    "                    data_aug_pct=0.8, \n",
    "                    steering_threshold=0.2, \n",
    "                    straight_steer_drop_prob=0.5,\n",
    "                    straight_steer_cal_prob=0.6,\n",
    "                     image_width=600, image_height=800, channel=1, num_features=2):\n",
    "    assert len(X_paths) == len(y_paths), f\"Dimension mismatch: Got {len(X_paths)} X but {len(y)} y\"\n",
    "    \n",
    "    \n",
    "    batch = np.zeros((batch_size, image_width, image_height, channel), dtype=np.float32)\n",
    "    labels = np.zeros((batch_size, num_features))\n",
    "    while True:\n",
    "        k = 0\n",
    "        while k < batch_size:\n",
    "            idx = np.random.randint(0, len(X_paths))\n",
    "            X_path, y_path = X_paths[idx], y_paths[idx]\n",
    "            b = load_depth(X_path)\n",
    "            t_s = load_state(y_path)[-2:]\n",
    "            t = t_s[0]\n",
    "            s = t_s[1]\n",
    "            \n",
    "            if abs(s) < steering_threshold and np.random.sample() < straight_steer_drop_prob:\n",
    "                continue\n",
    "            \n",
    "            if abs(s) < steering_threshold and np.random.sample() < straight_steer_cal_prob:\n",
    "                s = s + (np.random.sample() - 0.5) # sample() produces rand num in [0, 1] -> want [-0.5, 0.5]\n",
    "            batch[k] = b\n",
    "            labels[k] = [t,s]\n",
    "            k += 1\n",
    "        yield batch, np.clip(labels, -1, 1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6850aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generate_data(X_paths_train, y_paths_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8142ec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch = (16, 600, 800, 1) | Sample label = (16, 2)\n"
     ]
    }
   ],
   "source": [
    "batch, label = next(gen)\n",
    "print(f\"Sample batch = {np.shape(batch)} | Sample label = {np.shape(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da5d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(steerings: np.ndarray, title=\"Title\"):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "    ax.grid(True)\n",
    "    ax.set(title=title)\n",
    "    count, bins, _ = ax.hist(steerings, bins=25, histtype='bar')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_images(imgs, labels, cols=5, fig_size=(15, 5)):\n",
    "    rows = len(imgs) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=fig_size)\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            ax = axes[r, c]\n",
    "            img = imgs[cols * r + c] * 255\n",
    "            lb = labels[cols * r + c]\n",
    "            ax.imshow(img.astype(np.uint8))\n",
    "            ax.axis('on')\n",
    "            ax.set_aspect('equal')\n",
    "            ax.set(title=lb)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_sample_images(X, y):\n",
    "    gen = generate_images(X=X, y=y, batch_size=20)\n",
    "    b, s = next(gen)\n",
    "    show_images(b[0:20], s[0:20])\n",
    "\n",
    "\n",
    "def plot_results(hist, metrics, xlb, ylb, title, leg, fsize=(10, 5)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=fsize)\n",
    "    for m in metrics:\n",
    "        ax.plot(hist.history[m])\n",
    "\n",
    "    ax.set(xlabel=xlb, ylabel=ylb, title=title)\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    ax.legend(leg, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f0595",
   "metadata": {},
   "source": [
    "## Explore & Analyise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a9f50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen = generate_data(X_paths_train, y_paths_train, batch_size=100)\n",
    "b, control = next(gen)\n",
    "plot_hist(control,\"training steering & throttle distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09d874f",
   "metadata": {},
   "source": [
    "## Define model & start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae8572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import nvidia_model_throttle_steering\n",
    "m = nvidia_model_throttle_steering(input_shape=(600,800, 1))\n",
    "batch_size = 16\n",
    "train_gen = generate_data(X_paths_train, y_paths_train, batch_size)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"nvidia_model_throttle_and_steering.h5\", monitor=\"val_loss\", save_best_only=True\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='depth_nvidia_model_logs', histogram_freq=1, write_graph=True,\n",
    "        write_images=True, update_freq=1000, profile_batch=2,\n",
    "        embeddings_freq=0, embeddings_metadata=None)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8c7621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tests = np.array([load_depth(X_path)  for X_path in X_paths_test])\n",
    "y_tests = np.array([load_state(y_path)[-2:] for y_path in y_paths_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6a104",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.1446WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 0.1442\n",
      "Epoch 2/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0691Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0690 - val_loss: 0.0583\n",
      "Epoch 3/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0649WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0649\n",
      "Epoch 4/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0648Epoch 1/1000\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 0.0649 - val_loss: 0.1075\n",
      "Epoch 5/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 6/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 0.0610 - val_loss: 3.6473\n",
      "Epoch 7/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0619WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618\n",
      "Epoch 8/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0617 - val_loss: 0.0484\n",
      "Epoch 9/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618\n",
      "Epoch 10/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0615 - val_loss: 0.0484\n",
      "Epoch 11/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618\n",
      "Epoch 12/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0594 - val_loss: 0.0474\n",
      "Epoch 13/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0626WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0626\n",
      "Epoch 14/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0604 - val_loss: 0.0520\n",
      "Epoch 15/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0619WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0619\n",
      "Epoch 16/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0584 - val_loss: 0.0437\n",
      "Epoch 17/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 18/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0622Epoch 1/1000\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 0.0621 - val_loss: 0.0489\n",
      "Epoch 19/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 20/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 59s 296ms/step - loss: 0.0603 - val_loss: 0.0478\n",
      "Epoch 21/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 22/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 62s 311ms/step - loss: 0.0609 - val_loss: 0.0463\n",
      "Epoch 23/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 24/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 67s 335ms/step - loss: 0.0612 - val_loss: 0.0506\n",
      "Epoch 25/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 26/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 67s 337ms/step - loss: 0.0598 - val_loss: 0.0504\n",
      "Epoch 27/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0582WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0582\n",
      "Epoch 28/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 69s 346ms/step - loss: 0.0594 - val_loss: 0.0463\n",
      "Epoch 29/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 30/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 68s 341ms/step - loss: 0.0616 - val_loss: 0.0471\n",
      "Epoch 31/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 32/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 67s 337ms/step - loss: 0.0589 - val_loss: 0.0498\n",
      "Epoch 33/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 34/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 73s 363ms/step - loss: 0.0601 - val_loss: 0.0463\n",
      "Epoch 35/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 36/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 74s 369ms/step - loss: 0.0615 - val_loss: 0.0466\n",
      "Epoch 37/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 38/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 75s 374ms/step - loss: 0.0614 - val_loss: 0.0472\n",
      "Epoch 39/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 40/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 74s 368ms/step - loss: 0.0600 - val_loss: 0.0470\n",
      "Epoch 41/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 42/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 72s 360ms/step - loss: 0.0603 - val_loss: 0.0495\n",
      "Epoch 43/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 44/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 75s 376ms/step - loss: 0.0602 - val_loss: 0.0470\n",
      "Epoch 45/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 46/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 74s 372ms/step - loss: 0.0594 - val_loss: 6.8833\n",
      "Epoch 47/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 48/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 73s 366ms/step - loss: 0.0601 - val_loss: 0.0473\n",
      "Epoch 49/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 50/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 73s 364ms/step - loss: 0.0604 - val_loss: 0.0468\n",
      "Epoch 51/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 52/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 73s 363ms/step - loss: 0.0601 - val_loss: 0.0499\n",
      "Epoch 53/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 54/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 72s 358ms/step - loss: 0.0611 - val_loss: 0.0483\n",
      "Epoch 55/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 56/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 71s 356ms/step - loss: 0.0597 - val_loss: 0.0464\n",
      "Epoch 57/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 58/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 72s 358ms/step - loss: 0.0611 - val_loss: 0.0472\n",
      "Epoch 59/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 60/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 71s 356ms/step - loss: 0.0606 - val_loss: 0.0461\n",
      "Epoch 61/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 62/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617Epoch 1/1000\n",
      "200/200 [==============================] - 72s 359ms/step - loss: 0.0618 - val_loss: 0.0507\n",
      "Epoch 63/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 64/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 73s 364ms/step - loss: 0.0596 - val_loss: 0.0472\n",
      "Epoch 65/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 66/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 74s 372ms/step - loss: 0.0594 - val_loss: 0.0471\n",
      "Epoch 67/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 68/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 75s 374ms/step - loss: 0.0594 - val_loss: 0.0470\n",
      "Epoch 69/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0633WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0632\n",
      "Epoch 70/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 75s 376ms/step - loss: 0.0603 - val_loss: 0.0462\n",
      "Epoch 71/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0615\n",
      "Epoch 72/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0619Epoch 1/1000\n",
      "200/200 [==============================] - 74s 371ms/step - loss: 0.0619 - val_loss: 0.0454\n",
      "Epoch 73/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 74/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 77s 385ms/step - loss: 0.0604 - val_loss: 0.0485\n",
      "Epoch 75/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 76/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 78s 388ms/step - loss: 0.0615 - val_loss: 0.0469\n",
      "Epoch 77/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 78/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 78s 388ms/step - loss: 0.0592 - val_loss: 0.0463\n",
      "Epoch 79/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 80s 401ms/step - loss: 0.0586 - val_loss: 0.0471\n",
      "Epoch 81/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 82/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 78s 392ms/step - loss: 0.0594 - val_loss: 0.0484\n",
      "Epoch 83/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 84/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 78s 388ms/step - loss: 0.0606 - val_loss: 26.3670\n",
      "Epoch 85/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0581WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0580\n",
      "Epoch 86/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 74s 371ms/step - loss: 0.0611 - val_loss: 0.1537\n",
      "Epoch 87/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0622WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0620\n",
      "Epoch 88/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 60s 302ms/step - loss: 0.0594 - val_loss: 0.0462\n",
      "Epoch 89/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0603\n",
      "Epoch 90/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 59s 295ms/step - loss: 0.0602 - val_loss: 0.0468\n",
      "Epoch 91/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 92/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 59s 297ms/step - loss: 0.0599 - val_loss: 0.0472\n",
      "Epoch 93/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 94/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 0.0592 - val_loss: 0.0479\n",
      "Epoch 95/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 96/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0601 - val_loss: 0.0485\n",
      "Epoch 97/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 98/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.0612 - val_loss: 0.0454\n",
      "Epoch 99/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 100/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.0594 - val_loss: 0.0450\n",
      "Epoch 101/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 102/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.0601 - val_loss: 0.0479\n",
      "Epoch 103/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 104/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0591 - val_loss: 0.0478\n",
      "Epoch 105/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 106/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0592 - val_loss: 0.0498\n",
      "Epoch 107/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 108/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0611 - val_loss: 0.0475\n",
      "Epoch 109/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 110/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0597 - val_loss: 0.0486\n",
      "Epoch 111/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 112/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0615 - val_loss: 0.0468\n",
      "Epoch 113/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 114/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0602 - val_loss: 0.0472\n",
      "Epoch 115/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 116/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0614 - val_loss: 0.0468\n",
      "Epoch 117/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 118/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0591 - val_loss: 0.0470\n",
      "Epoch 119/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0581WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0583\n",
      "Epoch 120/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0577Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0577 - val_loss: 0.0453\n",
      "Epoch 121/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 122/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0610 - val_loss: 0.0463\n",
      "Epoch 123/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 124/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0601 - val_loss: 0.0465\n",
      "Epoch 125/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0621WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0621\n",
      "Epoch 126/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 57s 283ms/step - loss: 0.0589 - val_loss: 0.0462\n",
      "Epoch 127/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 128/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0614 - val_loss: 0.0479\n",
      "Epoch 129/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 130/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0594 - val_loss: 0.0460\n",
      "Epoch 131/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 132/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0606 - val_loss: 0.0477\n",
      "Epoch 133/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 134/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0595 - val_loss: 0.0477\n",
      "Epoch 135/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 136/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0611 - val_loss: 0.0480\n",
      "Epoch 137/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 138/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0603 - val_loss: 0.0469\n",
      "Epoch 139/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 140/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 0.0610 - val_loss: 0.0475\n",
      "Epoch 141/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 142/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0596 - val_loss: 0.0530\n",
      "Epoch 143/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 144/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0607 - val_loss: 0.0471\n",
      "Epoch 145/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 146/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0604 - val_loss: 0.0470\n",
      "Epoch 147/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0587\n",
      "Epoch 148/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0594 - val_loss: 0.0470\n",
      "Epoch 149/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 150/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0613 - val_loss: 0.0466\n",
      "Epoch 151/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 152/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0603 - val_loss: 0.0466\n",
      "Epoch 153/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 154/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 59s 295ms/step - loss: 0.0598 - val_loss: 1.2800\n",
      "Epoch 155/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 156/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0601 - val_loss: 0.0466\n",
      "Epoch 157/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0584\n",
      "Epoch 158/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 0.0600 - val_loss: 0.0459\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0589\n",
      "Epoch 160/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0604 - val_loss: 0.0490\n",
      "Epoch 161/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 162/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0602 - val_loss: 0.0439\n",
      "Epoch 163/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 164/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0606 - val_loss: 0.0483\n",
      "Epoch 165/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0617\n",
      "Epoch 166/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0593 - val_loss: 0.0496\n",
      "Epoch 167/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 168/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0601 - val_loss: 0.0479\n",
      "Epoch 169/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 170/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0601 - val_loss: 0.0459\n",
      "Epoch 171/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 172/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0597 - val_loss: 0.0484\n",
      "Epoch 173/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 174/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0603 - val_loss: 0.0465\n",
      "Epoch 175/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 176/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0601 - val_loss: 8.3349\n",
      "Epoch 177/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 178/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0597 - val_loss: 0.0450\n",
      "Epoch 179/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 180/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0615 - val_loss: 0.0480\n",
      "Epoch 181/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 182/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0619Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0618 - val_loss: 0.0472\n",
      "Epoch 183/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 184/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0598 - val_loss: 0.0475\n",
      "Epoch 185/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 186/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0592 - val_loss: 0.0463\n",
      "Epoch 187/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 188/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0596 - val_loss: 0.0477\n",
      "Epoch 189/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 190/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0598 - val_loss: 0.1396\n",
      "Epoch 191/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0587\n",
      "Epoch 192/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0600 - val_loss: 16.2714\n",
      "Epoch 193/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 194/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0590 - val_loss: 0.0497\n",
      "Epoch 195/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 196/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0599 - val_loss: 63.6357\n",
      "Epoch 197/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 198/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0608 - val_loss: 0.0481\n",
      "Epoch 199/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 200/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0601 - val_loss: 0.0472\n",
      "Epoch 201/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0612\n",
      "Epoch 202/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0591 - val_loss: 0.0465\n",
      "Epoch 203/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0617\n",
      "Epoch 204/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0606 - val_loss: 0.0478\n",
      "Epoch 205/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 206/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0613 - val_loss: 0.2192\n",
      "Epoch 207/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 208/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0602 - val_loss: 0.0486\n",
      "Epoch 209/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 210/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0590 - val_loss: 0.0475\n",
      "Epoch 211/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0626WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0625\n",
      "Epoch 212/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0619 - val_loss: 0.0477\n",
      "Epoch 213/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 214/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0625Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0625 - val_loss: 0.0474\n",
      "Epoch 215/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 216/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0598 - val_loss: 0.2141\n",
      "Epoch 217/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 218/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0605 - val_loss: 0.0487\n",
      "Epoch 219/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 220/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0598 - val_loss: 0.0462\n",
      "Epoch 221/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0575WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0576\n",
      "Epoch 222/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0598 - val_loss: 0.0461\n",
      "Epoch 223/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0620WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0620\n",
      "Epoch 224/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0600 - val_loss: 0.0451\n",
      "Epoch 225/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 226/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0608 - val_loss: 0.3357\n",
      "Epoch 227/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 228/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0598 - val_loss: 0.0456\n",
      "Epoch 229/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 230/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0598 - val_loss: 0.0473\n",
      "Epoch 231/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 232/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0603 - val_loss: 0.0472\n",
      "Epoch 233/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 234/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0605 - val_loss: 0.0480\n",
      "Epoch 235/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 236/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0605 - val_loss: 0.0470\n",
      "Epoch 237/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 238/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0611 - val_loss: 0.0484\n",
      "Epoch 239/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 240/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0591 - val_loss: 0.0483\n",
      "Epoch 241/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 242/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.0614 - val_loss: 0.0688\n",
      "Epoch 243/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0584\n",
      "Epoch 244/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 58s 290ms/step - loss: 0.0602 - val_loss: 0.0471\n",
      "Epoch 245/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 246/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0609 - val_loss: 63.2319\n",
      "Epoch 247/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 248/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0613 - val_loss: 0.0467\n",
      "Epoch 249/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 250/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0604 - val_loss: 0.0487\n",
      "Epoch 251/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 252/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0587 - val_loss: 0.0479\n",
      "Epoch 253/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 254/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0591 - val_loss: 0.0470\n",
      "Epoch 255/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 256/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0595 - val_loss: 0.0464\n",
      "Epoch 257/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 258/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0587 - val_loss: 0.0452\n",
      "Epoch 259/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 260/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0595 - val_loss: 0.0480\n",
      "Epoch 261/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 262/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0598 - val_loss: 14.8771\n",
      "Epoch 263/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 264/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 57s 283ms/step - loss: 0.0596 - val_loss: 0.0468\n",
      "Epoch 265/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 266/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0605 - val_loss: 0.0465\n",
      "Epoch 267/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 268/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0588 - val_loss: 0.0487\n",
      "Epoch 269/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 270/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0603 - val_loss: 0.0464\n",
      "Epoch 271/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 272/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0603 - val_loss: 0.0485\n",
      "Epoch 273/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0573WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0574\n",
      "Epoch 274/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0597 - val_loss: 0.0479\n",
      "Epoch 275/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 276/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0611 - val_loss: 0.0471\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 278/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0593 - val_loss: 0.0447\n",
      "Epoch 279/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 280/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0617 - val_loss: 0.4329\n",
      "Epoch 281/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 282/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0609 - val_loss: 0.0480\n",
      "Epoch 283/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 284/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0606 - val_loss: 0.0468\n",
      "Epoch 285/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 286/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0604 - val_loss: 0.0468\n",
      "Epoch 287/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0618\n",
      "Epoch 288/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0609 - val_loss: 0.0482\n",
      "Epoch 289/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618\n",
      "Epoch 290/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0611 - val_loss: 0.0472\n",
      "Epoch 291/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0576WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0577\n",
      "Epoch 292/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0603 - val_loss: 0.0468\n",
      "Epoch 293/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 294/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0604 - val_loss: 0.0478\n",
      "Epoch 295/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 296/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0611 - val_loss: 0.0473\n",
      "Epoch 297/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618\n",
      "Epoch 298/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0603 - val_loss: 0.0473\n",
      "Epoch 299/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 300/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0609 - val_loss: 0.0464\n",
      "Epoch 301/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 302/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0589 - val_loss: 2.6696\n",
      "Epoch 303/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 304/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0607 - val_loss: 0.0476\n",
      "Epoch 305/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0612\n",
      "Epoch 306/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0592 - val_loss: 0.0471\n",
      "Epoch 307/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0617\n",
      "Epoch 308/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0605 - val_loss: 0.0576\n",
      "Epoch 309/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 310/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0601 - val_loss: 0.0478\n",
      "Epoch 311/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0587\n",
      "Epoch 312/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0612 - val_loss: 0.0455\n",
      "Epoch 313/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 314/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0601 - val_loss: 0.0469\n",
      "Epoch 315/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 316/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0604 - val_loss: 0.0466\n",
      "Epoch 317/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 318/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0607 - val_loss: 0.0475\n",
      "Epoch 319/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0615\n",
      "Epoch 320/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0586 - val_loss: 0.0474\n",
      "Epoch 321/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 322/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0611 - val_loss: 0.0465\n",
      "Epoch 323/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 324/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0610 - val_loss: 0.0530\n",
      "Epoch 325/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 326/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0614 - val_loss: 0.0475\n",
      "Epoch 327/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 328/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0591 - val_loss: 0.0458\n",
      "Epoch 329/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 330/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0595 - val_loss: 0.0489\n",
      "Epoch 331/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 332/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0607 - val_loss: 0.0481\n",
      "Epoch 333/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 334/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0588 - val_loss: 0.0465\n",
      "Epoch 335/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 336/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0612 - val_loss: 0.0465\n",
      "Epoch 337/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 338/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0606 - val_loss: 0.0475\n",
      "Epoch 339/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 340/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0611 - val_loss: 0.0474\n",
      "Epoch 341/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 342/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0606 - val_loss: 0.0469\n",
      "Epoch 343/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 344/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0602 - val_loss: 0.0461\n",
      "Epoch 345/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0583\n",
      "Epoch 346/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0582Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0581 - val_loss: 0.0802\n",
      "Epoch 347/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 348/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0617 - val_loss: 0.0479\n",
      "Epoch 349/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 350/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0612 - val_loss: 0.0474\n",
      "Epoch 351/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 352/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0596 - val_loss: 0.0465\n",
      "Epoch 353/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0585\n",
      "Epoch 354/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0596 - val_loss: 0.0459\n",
      "Epoch 355/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 356/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0590 - val_loss: 0.0473\n",
      "Epoch 357/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0595\n",
      "Epoch 358/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0599 - val_loss: 0.0490\n",
      "Epoch 359/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0579WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0579\n",
      "Epoch 360/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0608 - val_loss: 0.0478\n",
      "Epoch 361/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 362/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0607 - val_loss: 0.0477\n",
      "Epoch 363/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 364/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0592 - val_loss: 0.0465\n",
      "Epoch 365/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 366/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0592 - val_loss: 0.0469\n",
      "Epoch 367/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 368/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0596 - val_loss: 0.0475\n",
      "Epoch 369/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 370/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0590 - val_loss: 0.0444\n",
      "Epoch 371/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 372/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0588 - val_loss: 0.0467\n",
      "Epoch 373/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 374/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0605 - val_loss: 0.0467\n",
      "Epoch 375/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 376/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0592 - val_loss: 0.0473\n",
      "Epoch 377/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618\n",
      "Epoch 378/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0588 - val_loss: 0.0472\n",
      "Epoch 379/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 380/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0596 - val_loss: 0.0475\n",
      "Epoch 381/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 382/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0596 - val_loss: 0.0466\n",
      "Epoch 383/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 384/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0602 - val_loss: 0.0470\n",
      "Epoch 385/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 386/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0618 - val_loss: 0.0494\n",
      "Epoch 387/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 388/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0608 - val_loss: 0.8280\n",
      "Epoch 389/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 390/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0602 - val_loss: 0.0483\n",
      "Epoch 391/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 392/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0603 - val_loss: 0.0474\n",
      "Epoch 393/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 394/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0604 - val_loss: 13.2869\n",
      "Epoch 395/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 396/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0603 - val_loss: 0.0478\n",
      "Epoch 397/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 398/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0597 - val_loss: 0.0469\n",
      "Epoch 399/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 400/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0611 - val_loss: 0.0484\n",
      "Epoch 401/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 402/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0599 - val_loss: 0.0482\n",
      "Epoch 403/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 404/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0582Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0583 - val_loss: 0.0462\n",
      "Epoch 405/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 406/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0587 - val_loss: 0.0457\n",
      "Epoch 407/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 408/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0609 - val_loss: 0.0470\n",
      "Epoch 409/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 410/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0610 - val_loss: 0.0474\n",
      "Epoch 411/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 412/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0616 - val_loss: 0.0469\n",
      "Epoch 413/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 414/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0603 - val_loss: 0.0486\n",
      "Epoch 415/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 416/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0588 - val_loss: 0.0457\n",
      "Epoch 417/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0581WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0581\n",
      "Epoch 418/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0625Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0625 - val_loss: 0.0463\n",
      "Epoch 419/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 420/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0603 - val_loss: 0.0474\n",
      "Epoch 421/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 422/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0599 - val_loss: 0.0477\n",
      "Epoch 423/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 424/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0595 - val_loss: 0.0477\n",
      "Epoch 425/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 426/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0597 - val_loss: 0.0470\n",
      "Epoch 427/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 428/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0597 - val_loss: 0.0472\n",
      "Epoch 429/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 430/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0586 - val_loss: 0.0461\n",
      "Epoch 431/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 432/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0603 - val_loss: 0.0478\n",
      "Epoch 433/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 434/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0587 - val_loss: 0.0467\n",
      "Epoch 435/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 436/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0609 - val_loss: 0.0471\n",
      "Epoch 437/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 438/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0603 - val_loss: 0.0473\n",
      "Epoch 439/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0619\n",
      "Epoch 440/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0596 - val_loss: 0.0470\n",
      "Epoch 441/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 442/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0593 - val_loss: 87063.3177\n",
      "Epoch 443/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 444/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0596 - val_loss: 0.0472\n",
      "Epoch 445/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 446/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0590 - val_loss: 0.0468\n",
      "Epoch 447/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 448/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0610 - val_loss: 0.0479\n",
      "Epoch 449/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 450/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0610 - val_loss: 0.0461\n",
      "Epoch 451/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 452/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0608 - val_loss: 0.0473\n",
      "Epoch 453/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0584\n",
      "Epoch 454/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0596 - val_loss: 0.0468\n",
      "Epoch 455/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 456/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0602 - val_loss: 0.0470\n",
      "Epoch 457/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0585\n",
      "Epoch 458/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0593 - val_loss: 0.0466\n",
      "Epoch 459/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 460/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0614 - val_loss: 0.0473\n",
      "Epoch 461/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 462/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0605 - val_loss: 0.0467\n",
      "Epoch 463/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 464/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0596 - val_loss: 0.0472\n",
      "Epoch 465/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 466/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0601 - val_loss: 0.0470\n",
      "Epoch 467/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0622WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0622\n",
      "Epoch 468/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0602 - val_loss: 0.0467\n",
      "Epoch 469/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 470/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0598 - val_loss: 0.0470\n",
      "Epoch 471/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 472/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0605 - val_loss: 0.0472\n",
      "Epoch 473/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 474/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0585 - val_loss: 0.0459\n",
      "Epoch 475/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 476/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0590 - val_loss: 0.0467\n",
      "Epoch 477/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 478/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0604 - val_loss: 0.0477\n",
      "Epoch 479/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 480/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0608 - val_loss: 0.0467\n",
      "Epoch 481/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 482/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0615 - val_loss: 0.0480\n",
      "Epoch 483/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 484/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0605 - val_loss: 0.0470\n",
      "Epoch 485/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 486/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0602 - val_loss: 0.0463\n",
      "Epoch 487/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 488/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0599 - val_loss: 0.0480\n",
      "Epoch 489/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 490/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0620Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0620 - val_loss: 35439.0091\n",
      "Epoch 491/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0623WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0623\n",
      "Epoch 492/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0595 - val_loss: 0.0471\n",
      "Epoch 493/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 494/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0603 - val_loss: 0.1040\n",
      "Epoch 495/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 496/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0587 - val_loss: 56.2779\n",
      "Epoch 497/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0586\n",
      "Epoch 498/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0615 - val_loss: 28.6873\n",
      "Epoch 499/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 500/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0597 - val_loss: 0.0476\n",
      "Epoch 501/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 502/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0598 - val_loss: 0.0469\n",
      "Epoch 503/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 504/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0588 - val_loss: 13.0421\n",
      "Epoch 505/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 506/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0605 - val_loss: 0.0468\n",
      "Epoch 507/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 508/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0619Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0619 - val_loss: 0.0476\n",
      "Epoch 509/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 510/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0587 - val_loss: 0.0473\n",
      "Epoch 511/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 512/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0614 - val_loss: 0.1621\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 514/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0585 - val_loss: 1.2217\n",
      "Epoch 515/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0589\n",
      "Epoch 516/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0603 - val_loss: 0.0475\n",
      "Epoch 517/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 518/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0595 - val_loss: 0.2620\n",
      "Epoch 519/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 520/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0600 - val_loss: 0.0475\n",
      "Epoch 521/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 522/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0610 - val_loss: 968.5754\n",
      "Epoch 523/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0584\n",
      "Epoch 524/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0595 - val_loss: 28.0288\n",
      "Epoch 525/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.0597\n",
      "Epoch 526/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0597 - val_loss: 0.0475\n",
      "Epoch 527/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 528/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0611 - val_loss: 0.0475\n",
      "Epoch 529/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 530/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617Epoch 1/1000\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.0617 - val_loss: 0.0467\n",
      "Epoch 531/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 532/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0596 - val_loss: 0.0476\n",
      "Epoch 533/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 534/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0599 - val_loss: 0.0468\n",
      "Epoch 535/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0620WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0619\n",
      "Epoch 536/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0594 - val_loss: 0.0475\n",
      "Epoch 537/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 538/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.0586 - val_loss: 0.0464\n",
      "Epoch 539/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0580WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0579\n",
      "Epoch 540/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0585 - val_loss: 0.0461\n",
      "Epoch 541/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 542/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0608 - val_loss: 0.0466\n",
      "Epoch 543/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 544/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.0589 - val_loss: 0.0468\n",
      "Epoch 545/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 546/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0605 - val_loss: 0.0471\n",
      "Epoch 547/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 548/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.0596 - val_loss: 0.0495\n",
      "Epoch 549/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 550/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0605 - val_loss: 0.0477\n",
      "Epoch 551/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0606 - val_loss: 0.0470\n",
      "Epoch 553/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 554/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0593 - val_loss: 0.0464\n",
      "Epoch 555/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 556/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0597 - val_loss: 0.0469\n",
      "Epoch 557/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0603\n",
      "Epoch 558/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0605 - val_loss: 0.0471\n",
      "Epoch 559/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 560/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0602 - val_loss: 0.0470\n",
      "Epoch 561/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 562/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0598 - val_loss: 0.0471\n",
      "Epoch 563/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 564/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0606 - val_loss: 0.0477\n",
      "Epoch 565/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 566/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0609 - val_loss: 0.0470\n",
      "Epoch 567/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 568/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0594 - val_loss: 0.0476\n",
      "Epoch 569/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 570/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0593 - val_loss: 0.0468\n",
      "Epoch 571/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0579WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0578\n",
      "Epoch 572/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0593 - val_loss: 0.0471\n",
      "Epoch 573/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 574/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0599 - val_loss: 0.6243\n",
      "Epoch 575/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 576/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0598 - val_loss: 0.0476\n",
      "Epoch 577/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 578/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0598 - val_loss: 0.0477\n",
      "Epoch 579/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 580/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0598 - val_loss: 0.0476\n",
      "Epoch 581/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0617\n",
      "Epoch 582/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0603 - val_loss: 0.0470\n",
      "Epoch 583/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0589\n",
      "Epoch 584/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0606 - val_loss: 0.0473\n",
      "Epoch 585/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0612\n",
      "Epoch 586/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0587 - val_loss: 0.0474\n",
      "Epoch 587/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 588/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0590 - val_loss: 0.0470\n",
      "Epoch 589/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 590/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0597 - val_loss: 0.0493\n",
      "Epoch 591/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 592/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0607 - val_loss: 0.0473\n",
      "Epoch 593/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 594/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0619 - val_loss: 0.0484\n",
      "Epoch 595/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0589\n",
      "Epoch 596/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 0.0593 - val_loss: 0.0466\n",
      "Epoch 597/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 598/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0604 - val_loss: 0.0470\n",
      "Epoch 599/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 600/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0599 - val_loss: 0.0466\n",
      "Epoch 601/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 602/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0602 - val_loss: 0.0470\n",
      "Epoch 603/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 604/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0592 - val_loss: 0.0463\n",
      "Epoch 605/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 606/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0607 - val_loss: 0.0469\n",
      "Epoch 607/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 608/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0582Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0582 - val_loss: 469.2914\n",
      "Epoch 609/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0587\n",
      "Epoch 610/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0602 - val_loss: 457.0368\n",
      "Epoch 611/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 612/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0607 - val_loss: 0.0482\n",
      "Epoch 613/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 614/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0592 - val_loss: 0.0502\n",
      "Epoch 615/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 616/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0613 - val_loss: 0.0487\n",
      "Epoch 617/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 618/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0599 - val_loss: 0.0486\n",
      "Epoch 619/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 620/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0611 - val_loss: 0.0453\n",
      "Epoch 621/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 622/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0610 - val_loss: 0.0467\n",
      "Epoch 623/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 624/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0600 - val_loss: 0.0490\n",
      "Epoch 625/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 626/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0611 - val_loss: 0.0463\n",
      "Epoch 627/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0612\n",
      "Epoch 628/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 0.0617 - val_loss: 0.0478\n",
      "Epoch 629/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 630/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0590 - val_loss: 0.0458\n",
      "Epoch 631/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0596\n",
      "Epoch 632/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0612 - val_loss: 0.8746\n",
      "Epoch 633/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 634/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0604 - val_loss: 0.0470\n",
      "Epoch 635/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 636/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0595 - val_loss: 0.0464\n",
      "Epoch 637/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0583\n",
      "Epoch 638/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0616 - val_loss: 0.0479\n",
      "Epoch 639/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 640/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0600 - val_loss: 0.0467\n",
      "Epoch 641/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0569WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0569\n",
      "Epoch 642/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0605 - val_loss: 0.0465\n",
      "Epoch 643/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0581WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0580\n",
      "Epoch 644/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0605 - val_loss: 216.8349\n",
      "Epoch 645/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 646/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0604 - val_loss: 0.0462\n",
      "Epoch 647/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 648/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0593 - val_loss: 0.0458\n",
      "Epoch 649/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 650/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0589 - val_loss: 0.0464\n",
      "Epoch 651/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 652/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0615 - val_loss: 0.0473\n",
      "Epoch 653/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 654/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0593 - val_loss: 0.0477\n",
      "Epoch 655/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 656/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0605 - val_loss: 0.0477\n",
      "Epoch 657/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0576WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0577\n",
      "Epoch 658/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0611 - val_loss: 0.0477\n",
      "Epoch 659/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 660/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0589 - val_loss: 0.0469\n",
      "Epoch 661/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0585\n",
      "Epoch 662/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0604 - val_loss: 0.0474\n",
      "Epoch 663/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 664/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0596 - val_loss: 0.0469\n",
      "Epoch 665/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 666/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0609 - val_loss: 9.2986\n",
      "Epoch 667/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 668/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0622Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0624 - val_loss: 0.0472\n",
      "Epoch 669/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0623WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0623\n",
      "Epoch 670/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0605 - val_loss: 0.0458\n",
      "Epoch 671/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 672/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0611 - val_loss: 0.0463\n",
      "Epoch 673/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 674/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0594 - val_loss: 0.0480\n",
      "Epoch 675/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 676/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0601 - val_loss: 0.0458\n",
      "Epoch 677/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 678/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0595 - val_loss: 113.5214\n",
      "Epoch 679/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 680/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0594 - val_loss: 0.0500\n",
      "Epoch 681/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 682/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0591 - val_loss: 997.0543\n",
      "Epoch 683/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 684/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0595 - val_loss: 0.0469\n",
      "Epoch 685/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 686/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0600 - val_loss: 0.0472\n",
      "Epoch 687/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0576WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0577\n",
      "Epoch 688/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0598 - val_loss: 0.0478\n",
      "Epoch 689/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 690/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0596 - val_loss: 9.0266\n",
      "Epoch 691/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 692/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0591 - val_loss: 135522.8281\n",
      "Epoch 693/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 694/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0596 - val_loss: 0.0459\n",
      "Epoch 695/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0589\n",
      "Epoch 696/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0606 - val_loss: 15.5055\n",
      "Epoch 697/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 698/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0602 - val_loss: 0.0581\n",
      "Epoch 699/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 700/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0598 - val_loss: 320.8177\n",
      "Epoch 701/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 702/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0607 - val_loss: 0.0471\n",
      "Epoch 703/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 704/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0590 - val_loss: 0.0475\n",
      "Epoch 705/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 706/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0588 - val_loss: 0.0477\n",
      "Epoch 707/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0587\n",
      "Epoch 708/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0591 - val_loss: 0.0469\n",
      "Epoch 709/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 710/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0598 - val_loss: 0.0477\n",
      "Epoch 711/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 712/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0603 - val_loss: 0.0470\n",
      "Epoch 713/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 714/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0600 - val_loss: 15.4116\n",
      "Epoch 715/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 716/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0608 - val_loss: 0.0464\n",
      "Epoch 717/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 718/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0601 - val_loss: 149.0296\n",
      "Epoch 719/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 720/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0597 - val_loss: 0.0457\n",
      "Epoch 721/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 722/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0596 - val_loss: 0.0475\n",
      "Epoch 723/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 724/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0620Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0620 - val_loss: 0.0470\n",
      "Epoch 725/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0615\n",
      "Epoch 726/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0599 - val_loss: 0.0474\n",
      "Epoch 727/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0585\n",
      "Epoch 728/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0598 - val_loss: 0.0499\n",
      "Epoch 729/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.0590\n",
      "Epoch 730/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      " 16/200 [=>............................] - ETA: 2:02 - loss: 86.0013"
     ]
    }
   ],
   "source": [
    "history = m.fit(train_gen, \n",
    "                verbose=1, \n",
    "                callbacks=callbacks, \n",
    "                steps_per_epoch = 200, \n",
    "                epochs=1000,\n",
    "                validation_data=(X_tests, y_tests), validation_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "805dc19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_results(history, [\"loss\", \"val_loss\"], \"loss\", \"val_loss\", \"loss vs val_loss\", [\"loss\", \"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37594d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac36dbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac732562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad356fe7",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a564794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_val = generate_images(X_test, y_test, batch_size)\n",
    "batch, steerings = next(gen_val)\n",
    "show_images(batch[0:20], steerings[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6780f85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33575627  0.3350542 ]\n",
      " [ 0.42153466 -0.12509304]\n",
      " [ 0.42961594  0.09497067]\n",
      " [ 0.52219    -0.21547362]\n",
      " [ 0.37239212  0.08458566]\n",
      " [ 0.15578039  0.31990615]\n",
      " [ 0.24405767  0.07524973]\n",
      " [ 0.11092788  0.37889016]\n",
      " [ 0.6845945   0.11776495]\n",
      " [ 0.24191844 -0.11903911]\n",
      " [ 0.0453493  -0.07521864]\n",
      " [ 0.3854706  -0.294028  ]\n",
      " [ 0.01533835  0.3077331 ]\n",
      " [ 0.23651096  0.30365494]\n",
      " [ 0.3854706  -0.294028  ]\n",
      " [ 0.4121667   0.14179194]\n",
      " [ 0.24405767  0.07524973]\n",
      " [ 0.22273293 -0.21498868]\n",
      " [ 0.15311469 -0.08078137]\n",
      " [ 0.37344056 -0.09682245]]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array(m.predict(batch[0:20])).squeeze()\n",
    "predictions = predictions.squeeze()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86968859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.06362296, 1.84429802])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(sum((predictions - steerings[0:20]) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98bd73c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"depth_model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf882d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fd903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11e90062",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[404736,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-41253a56d2c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"depth_nvidia_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    205\u001b[0m           (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m    206\u001b[0m         return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n\u001b[0;32m--> 207\u001b[0;31m                                                 compile)\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[0;32m--> 184\u001b[0;31m                                                custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     62\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    356\u001b[0m             custom_objects=dict(\n\u001b[1;32m    357\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    492\u001b[0m       layer = layer_module.deserialize(layer_config,\n\u001b[1;32m    493\u001b[0m                                        custom_objects=custom_objects)\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m     if (not model.inputs and build_input_shape and\n\u001b[1;32m    496\u001b[0m         isinstance(build_input_shape, (tuple, list))):\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2712\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         trainable=True)\n\u001b[0m\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    640\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         shape=None):\n\u001b[1;32m    198\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2616\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2618\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2619\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1583\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1710\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \"\"\"\n\u001b[1;32m    409\u001b[0m     return super(VarianceScaling, self).__call__(\n\u001b[0;32m--> 410\u001b[0;31m         shape, dtype=_get_dtype(dtype), **kwargs)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     return op(\n\u001b[0;32m-> 1082\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    306\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[404736,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]"
     ]
    }
   ],
   "source": [
    "m = tf.keras.models.load_model(\"depth_nvidia_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6154b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610492ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
